{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76fdb13-b1fc-435b-9374-0bb1b3809390",
   "metadata": {},
   "source": [
    "\n",
    "# Lab5: Bagging Random Forest and Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b86be9",
   "metadata": {},
   "source": [
    "\n",
    "We import some of our usual libraries at this top\n",
    "level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5061d7d5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as skm\n",
    "import ISLP\n",
    "from ISLP import load_data, confusion_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffeb1c",
   "metadata": {},
   "source": [
    "We also  collect the new imports\n",
    "needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "747b056a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RFR,\n",
    "      GradientBoostingRegressor as GBR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561512e-9752-43b6-84c2-42e914b686a9",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "\n",
    "Suppose we produce ten boostrapped samples form a data set containing red and green classes. We then apply a classification tree to each bosstrapped sample and, for a specific value of $x$, produce 10 estimates of $P(\\text{Calls is Red}|x)$ : \n",
    "\\[0.1,0.15,0.2,0.2,0.55,0.6,0.6,0.65,0.7,0.75\\]\n",
    "Using the majority vote approach discussed in the course, what is the final prediction for this $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e4849",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "In the exercise,  we will\n",
    "seek to predict Sales (Carseats data) using regression trees and related approaches.\n",
    "1. Split the data set into a training set and a test set\n",
    "2. Use the bagging approach in order to analyse this data (What is the number of trees what you use ?) . What test MSE do you obtain ? Use Feature_importance_ values to determine which variables are most important.\n",
    "3. Use the random forest  approach in order to analyse this data. What test MSE do you obtain ? Use Feature_importance_ values to determine which variables are most important. Describe the effect of $m$, the number of variables considered at each split, in the error rate obtained.\n",
    "4. Use the boostingt  approach in order to analyse this data. What test MSE do you obtain ? Which features appear to be the most important.\n",
    "5. What is the best model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Carseats = pd.read_csv(\"../Data/Carseats.csv\")\n",
    "Carseats.shape\n",
    "# create Dummies Variables to transform Qualitative/categortial variables in 0-1 variables\n",
    "dummies = pd.get_dummies(Carseats[[\"ShelveLoc\", \"Urban\", \"US\"]]).astype(\"float64\")\n",
    "\n",
    "# Drop the column with the independent variable (Sales), and columns for which we created dummy variables\n",
    "X_ = Carseats.drop([\"Sales\", \"ShelveLoc\", \"Urban\", \"US\"], axis=1).astype(\"float64\")\n",
    "\n",
    "\n",
    "# Define the feature set X and transform it in an array\n",
    "D = pd.concat(\n",
    "    [X_, dummies[[\"ShelveLoc_Good\", \"ShelveLoc_Medium\", \"Urban_Yes\", \"US_Yes\"]]], axis=1\n",
    ")\n",
    "X = np.asarray(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34bf2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 1 \n",
    "# Split dataset into training and test part\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Carseats['Sales'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275feef7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Question 2 Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbbef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3523e-ff75-46cc-b947-d98074866a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a5ed4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#question 3 Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71316e9a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782d22c-eda5-4039-b3d3-b2f7f66cccd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43505dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df398d7-5e75-4c17-a065-285fea3785e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd24545-df91-4c7e-ae88-b1b1111834e6",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "\n",
    "Do the same with OJ data with classifier instead of a regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e45a6f-4f17-4ae2-83a4-debee13ed486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b509ec-c12e-4ff1-b4b4-d2bd2db53451",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "\n",
    "Apply the methodologies (PLS or PCR, Bagging, RF or Boosting) to a data set of your choice.\n",
    "Be sure to fit the models on a training set and to evaluate the performance on a test set. How accurate are the results compared to simple methods like linear regression. Which of thse approaches yields the best performance ?\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "Rmd,ipynb",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
